{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31m2025-01-31 15:07:49.429923553 [E:onnxruntime:Default, provider_bridge_ort.cc:1992 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1637 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn.so.9: cannot open shared object file: No such file or directory\n",
      "\u001b[m\n",
      "\u001b[0;93m2025-01-31 15:07:49.429941083 [W:onnxruntime:Default, onnxruntime_pybind_state.cc:965 CreateExecutionProviderInstance] Failed to create CUDAExecutionProvider. Require cuDNN 9.* and CUDA 12.*. Please install all dependencies as mentioned in the GPU requirements page (https://onnxruntime.ai/docs/execution-providers/CUDA-ExecutionProvider.html#requirements), make sure they're in the PATH, and that your GPU is supported.\u001b[m\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "from typing import List\n",
    "\n",
    "class DistractionDetector:\n",
    "    def __init__(self, model_path: str, input_name: str, input_width: int, input_height: int):\n",
    "        self.session = ort.InferenceSession(model_path, providers=[\"CUDAExecutionProvider\"])\n",
    "        self.input_name = input_name\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "\n",
    "        self.class_dict = {\n",
    "            0: \"safe driving\",\n",
    "            1: \"texting\",\n",
    "            2: \"talking on the phone\",\n",
    "            3: \"drinking\",\n",
    "            4: \"reaching behind\",\n",
    "        }\n",
    "        self.outputs_softmax = []\n",
    "\n",
    "    def softmax(self, x: np.ndarray, axis: int) -> np.ndarray:\n",
    "        x = x - np.max(x, axis=axis, keepdims=True)\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=axis, keepdims=True)\n",
    "\n",
    "    def run_inference(self, frame: np.ndarray) -> List[float]:\n",
    "        # Convert to grayscale (single channel)\n",
    "        #Convert to grayscale\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)  # Shape: (H, W)\n",
    "        frame_gray = np.expand_dims(frame_gray, axis=-1)  # Shape: (H, W, 1), matches Torchvision Grayscale\n",
    "\n",
    "        # Resize to 224x224\n",
    "        resized_frame = cv2.resize(frame_gray, (self.input_width, self.input_height))\n",
    "\n",
    "        # Convert to float32 and normalize to [-1, 1] (same as Torchvision Normalize((0.5,), (0.5,)))\n",
    "        normalized_frame = resized_frame.astype(np.float32) / 255.0  # Scale to [0,1]\n",
    "        normalized_frame = (normalized_frame - 0.5) / 0.5  # Normalize to [-1, 1]\n",
    "\n",
    "        # Expand grayscale image to 3 channels (Replicating it across 3 channels)\n",
    "        expanded_frame = np.repeat(normalized_frame[:, :, np.newaxis], 3, axis=-1)\n",
    "\n",
    "        # Convert to (C, H, W) format for the model\n",
    "        chw_frame = np.transpose(expanded_frame, (2, 0, 1))\n",
    "\n",
    "        # Convert to tensor format for ONNX inference\n",
    "        input_tensor = np.expand_dims(chw_frame, axis=0).astype(np.float32)\n",
    "\n",
    "        # Display the grayscale normalized image before inference        display_frame = (((normalized_frame ) * 255)).astype(np.uint16)  # Convert back to [0,255] for display\n",
    "    \n",
    "\n",
    "        # Run inference\n",
    "        outputs = self.session.run(None, {self.input_name: input_tensor})\n",
    "        logits = outputs[0][0]\n",
    "        self.outputs_softmax = self.softmax(logits, axis=0).tolist()\n",
    "        return self.outputs_softmax\n",
    "\n",
    "    def display_probabilities(self, probabilities: List[float]):\n",
    "        for class_index, class_name in self.class_dict.items():\n",
    "            print(f\"{class_name}: {probabilities[class_index]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = \"/home/theosiam/Repos/Autotrust/Autotrust/Driver_Distraction_Detection/Onnx_versions/onnx_version5.onnx\"\n",
    "    input_name = \"input\"\n",
    "    input_width, input_height = 224, 224\n",
    "    detector = DistractionDetector(model_path, input_name, input_width, input_height)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam.\")\n",
    "        exit()\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture image.\")\n",
    "            break\n",
    "\n",
    "        probabilities = detector.run_inference(frame)\n",
    "        label = max(detector.class_dict, key=lambda i: probabilities[i])\n",
    "        text = f\"{detector.class_dict[label]} ({probabilities[label]:.2f})\"\n",
    "        cv2.putText(frame, text, (10, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "        cv2.imshow(\"Distraction Detector\", frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dddsc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
